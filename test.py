import os
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import base64
from io import BytesIO
import threading

os.environ["SD_ENABLE_ASIO"] = "1"
import sounddevice as sd

# --- ì„¤ì • ---
ASIO_DEVICE_ID = 18
SAMPLE_RATE = 44100
RECORD_DURATION = 10  # 10ì´ˆ ë…¹ìŒ
SOFTWARE_GAIN = 60.0
METRONOME_BPM = 120  # ë©”íŠ¸ë¡œë†ˆ BPM
CHROMATIC_ENABLED = True  # í¬ë¡œë§¤í‹± í´ë¦­ í™œì„±í™”

# ë…¹ìŒ ë²„í¼
recorded_data = []

# ë©”íŠ¸ë¡œë†ˆ ì‚¬ìš´ë“œ ìƒì„±
def generate_metronome_click(duration_ms=50, frequency=1000, sample_rate=44100):
    """ë©”íŠ¸ë¡œë†ˆ í´ë¦­ ì‚¬ìš´ë“œ ìƒì„± (ê°•ë°•ìš©)"""
    samples = int(sample_rate * duration_ms / 1000)
    t = np.linspace(0, duration_ms/1000, samples, False)
    # ì‚¬ì¸íŒŒ + ì—”ë²¨ë¡œí”„
    tone = np.sin(2 * np.pi * frequency * t)
    envelope = np.exp(-10 * t)  # ë¹ ë¥´ê²Œ ê°ì‡ 
    return (tone * envelope * 0.3).astype(np.float32)

def generate_chromatic_click(duration_ms=30, frequency=1500, sample_rate=44100):
    """í¬ë¡œë§¤í‹± í´ë¦­ ì‚¬ìš´ë“œ ìƒì„± (ì•½ë°•ìš© - ë†’ì€ ìŒ)"""
    samples = int(sample_rate * duration_ms / 1000)
    t = np.linspace(0, duration_ms/1000, samples, False)
    # ë” ë†’ì€ ì£¼íŒŒìˆ˜ + ì§§ì€ ì§€ì†ì‹œê°„
    tone = np.sin(2 * np.pi * frequency * t)
    envelope = np.exp(-15 * t)  # ë” ë¹ ë¥´ê²Œ ê°ì‡ 
    return (tone * envelope * 0.2).astype(np.float32)

# ë¯¸ë¦¬ ì‚¬ìš´ë“œ ìƒì„±
METRONOME_SOUND = generate_metronome_click()  # ê°•ë°• (1ë°•)
CHROMATIC_SOUND = generate_chromatic_click()   # ì•½ë°• (í¬ë¡œë§¤í‹±)

# ë©”íŠ¸ë¡œë†ˆ ìƒíƒœ
metronome_active = False
current_beat = 0
beat_interval_samples = 0
sample_counter = 0

def audio_callback(indata, outdata, frames, time_info, status):
    global recorded_data, metronome_active, current_beat, sample_counter
    
    # ì…ë ¥ ì¦í­
    guitar_input = indata[:, 0]
    amplified = np.clip(guitar_input * SOFTWARE_GAIN, -1.0, 1.0)
    
    # ë…¹ìŒ
    recorded_data.extend(amplified)
    
    # ë©”íŠ¸ë¡œë†ˆ + ê¸°íƒ€ ë¯¹ìŠ¤
    output_signal = amplified.copy()
    
    if metronome_active:
        # ê° í”„ë ˆì„ë§ˆë‹¤ ë°•ì ì²´í¬
        for i in range(frames):
            if sample_counter >= beat_interval_samples:
                sample_counter = 0
                current_beat = (current_beat + 1) % 4
            sample_counter += 1
        
        # í´ë¦­ ì‚¬ìš´ë“œ ì‚½ì…
        if sample_counter < len(METRONOME_SOUND):
            # ì†Œì ˆ ì²« ë°• (1ë°•) - ê°•í•œ í´ë¦­
            if current_beat == 0:
                click_len = min(len(METRONOME_SOUND) - sample_counter, frames)
                output_signal[:click_len] += METRONOME_SOUND[sample_counter:sample_counter + click_len]
            # ë‚˜ë¨¸ì§€ ë°• - ì•½í•œ í´ë¦­
            else:
                click_len = min(len(METRONOME_SOUND) - sample_counter, frames)
                output_signal[:click_len] += METRONOME_SOUND[sample_counter:sample_counter + click_len] * 0.6
        
        # í¬ë¡œë§¤í‹± í´ë¦­ (8ë¶„ìŒí‘œ - ë°• ì‚¬ì´)
        if CHROMATIC_ENABLED:
            chromatic_position = beat_interval_samples // 2
            if chromatic_position - 100 < sample_counter < chromatic_position + len(CHROMATIC_SOUND):
                offset = sample_counter - chromatic_position
                if 0 <= offset < frames:
                    click_len = min(len(CHROMATIC_SOUND) - offset, frames - offset)
                    if click_len > 0 and offset >= 0:
                        output_signal[offset:offset + click_len] += CHROMATIC_SOUND[:click_len]
    
    # ì¶œë ¥
    output_signal = np.clip(output_signal, -1.0, 1.0)
    for i in range(outdata.shape[1]):
        outdata[:, i] = output_signal

def create_waveform_with_metronome(audio_data, bpm, sample_rate):
    """íŒŒí˜•ê³¼ ë©”íŠ¸ë¡œë†ˆ ê·¸ë¦¬ë“œë¥¼ ì‹œê°í™”"""
    duration = len(audio_data) / sample_rate
    time_axis = np.linspace(0, duration, len(audio_data))
    
    # Figure ì„¤ì •
    fig, ax = plt.subplots(figsize=(18, 7), dpi=100)
    
    # íŒŒí˜• ê·¸ë¦¬ê¸°
    ax.plot(time_axis, audio_data, color='#2E86DE', linewidth=0.5, alpha=0.8)
    ax.fill_between(time_axis, audio_data, alpha=0.3, color='#2E86DE')
    
    # ì—”ë²¨ë¡œí”„ ì¶”ê°€ (íƒ€ê²© ì§€ì  ê°•ì¡°)
    envelope = np.abs(audio_data)
    window_size = int(sample_rate * 0.01)  # 10ms ìœˆë„ìš°
    smoothed = np.convolve(envelope, np.ones(window_size)/window_size, mode='same')
    ax.plot(time_axis, smoothed, color='#E74C3C', linewidth=1.5, 
            alpha=0.6, label='Attack Envelope')
    
    # ë©”íŠ¸ë¡œë†ˆ ê·¸ë¦¬ë“œ (4/4ë°•ì)
    beat_interval = 60.0 / bpm  # ì´ˆ ë‹¨ìœ„ (1ë°•)
    chromatic_interval = beat_interval / 2  # 8ë¶„ìŒí‘œ
    
    # 1ë°• ë‹¨ìœ„ (ê°•ë°•/ì•½ë°•)
    beat_positions = np.arange(0, duration, beat_interval)
    for i, beat_pos in enumerate(beat_positions):
        # ì†Œì ˆ ì²« ë°•ì€ ë¹¨ê°„ìƒ‰, ë‚˜ë¨¸ì§€ëŠ” ì£¼í™©ìƒ‰
        color = '#FF6B6B' if i % 4 == 0 else '#FFA502'
        linewidth = 2.5 if i % 4 == 0 else 1.5
        alpha = 0.8 if i % 4 == 0 else 0.6
        ax.axvline(beat_pos, color=color, linestyle='--', 
                   linewidth=linewidth, alpha=alpha)
    
    # í¬ë¡œë§¤í‹± ê·¸ë¦¬ë“œ (8ë¶„ìŒí‘œ - ë°• ì‚¬ì´)
    if CHROMATIC_ENABLED:
        chromatic_positions = np.arange(chromatic_interval, duration, beat_interval)
        for chrom_pos in chromatic_positions:
            ax.axvline(chrom_pos, color='#95A5A6', linestyle=':', 
                       linewidth=1, alpha=0.5)
    
    # ìŠ¤íƒ€ì¼ë§
    ax.set_xlim(0, duration)
    ax.set_ylim(-1.1, 1.1)
    ax.set_xlabel('Time (seconds)', fontsize=13, fontweight='bold')
    ax.set_ylabel('Amplitude', fontsize=13, fontweight='bold')
    
    title = f'Guitar Performance Analysis | {bpm} BPM'
    if CHROMATIC_ENABLED:
        title += ' (Chromatic Grid Enabled)'
    ax.set_title(title, fontsize=15, fontweight='bold', pad=20)
    
    ax.grid(True, alpha=0.2, linestyle='-', linewidth=0.5)
    ax.set_facecolor('#F8F9FA')
    
    # ë²”ë¡€
    from matplotlib.patches import Patch
    legend_elements = [
        Patch(facecolor='#2E86DE', alpha=0.3, label='Guitar Signal'),
        plt.Line2D([0], [0], color='#E74C3C', linewidth=1.5, label='Attack Envelope'),
        plt.Line2D([0], [0], color='#FF6B6B', linestyle='--', linewidth=2.5, label='Downbeat (1ë°•)'),
        plt.Line2D([0], [0], color='#FFA502', linestyle='--', linewidth=1.5, label='Beat (2,3,4ë°•)'),
    ]
    if CHROMATIC_ENABLED:
        legend_elements.append(
            plt.Line2D([0], [0], color='#95A5A6', linestyle=':', label='Chromatic (8ë¶„ìŒí‘œ)')
        )
    ax.legend(handles=legend_elements, loc='upper right', fontsize=10)
    
    plt.tight_layout()
    return fig

def fig_to_base64(fig):
    """Figureë¥¼ base64 ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
    buf = BytesIO()
    fig.savefig(buf, format='png', dpi=150, bbox_inches='tight')
    buf.seek(0)
    img_base64 = base64.b64encode(buf.read()).decode('utf-8')
    buf.close()
    return img_base64

def save_analysis_image(fig, filename=None):
    """ì´ë¯¸ì§€ ì €ì¥"""
    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"guitar_chromatic_{timestamp}.png"
    
    fig.savefig(filename, dpi=150, bbox_inches='tight')
    print(f"âœ“ ì´ë¯¸ì§€ ì €ì¥: {filename}")
    return filename

def record_and_analyze():
    global recorded_data, metronome_active, current_beat, sample_counter, beat_interval_samples
    recorded_data = []
    current_beat = 0
    sample_counter = 0
    
    # ë°•ì ê°„ê²© ê³„ì‚°
    beat_interval_samples = int(SAMPLE_RATE * 60.0 / METRONOME_BPM)
    
    print(f"{'='*70}")
    print(f"ğŸ¸ í¬ë¡œë§¤í‹± ê¸°íƒ€ ì—°ì£¼ ë¶„ì„ê¸° ({METRONOME_BPM} BPM)")
    print(f"{'='*70}")
    print(f"ğŸ“Š ë…¹ìŒ ì‹œê°„: {RECORD_DURATION}ì´ˆ")
    print(f"ğŸµ ë°•ì: 4/4ë°•ì")
    print(f"âœ¨ í¬ë¡œë§¤í‹± ê·¸ë¦¬ë“œ: {'í™œì„±í™” (8ë¶„ìŒí‘œ)' if CHROMATIC_ENABLED else 'ë¹„í™œì„±í™”'}")
    print(f"{'='*70}\n")
    
    try:
        info = sd.query_devices(ASIO_DEVICE_ID)
        channels = min(info['max_input_channels'], info['max_output_channels'])
        
        # ë…¹ìŒ
        with sd.Stream(device=ASIO_DEVICE_ID,
                       samplerate=SAMPLE_RATE,
                       blocksize=512,
                       dtype='float32',
                       channels=channels,
                       callback=audio_callback):
            
            # ë©”íŠ¸ë¡œë†ˆ í™œì„±í™”
            metronome_active = True
            
            print("ğŸ¼ ë©”íŠ¸ë¡œë†ˆ ì‹œì‘! í¬ë¡œë§¤í‹± ì—°ì£¼ë¥¼ ì‹œì‘í•˜ì„¸ìš”!")
            print("   (ê°•ë°• = í° ì†Œë¦¬, ì•½ë°• = ì¤‘ê°„ ì†Œë¦¬, í¬ë¡œë§¤í‹± = ì‘ì€ í‹±)")
            print()
            
            for i in range(RECORD_DURATION, 0, -1):
                bar = 'â–ˆ' * (RECORD_DURATION - i + 1) + 'â–‘' * (i - 1)
                print(f"  â±ï¸  [{bar}] {i:2d}ì´ˆ ë‚¨ìŒ", end='\r')
                sd.sleep(1000)
            
            metronome_active = False
        
        print("\n\nâœ“ ë…¹ìŒ ì™„ë£Œ! ë¶„ì„ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        
        # íŒŒí˜• ì´ë¯¸ì§€ ìƒì„±
        audio_array = np.array(recorded_data)
        fig = create_waveform_with_metronome(audio_array, METRONOME_BPM, SAMPLE_RATE)
        
        # ì´ë¯¸ì§€ ì €ì¥
        filename = save_analysis_image(fig)
        
        # base64 ì¸ì½”ë”© (Claude API ì „ì†¡ìš©)
        img_base64 = fig_to_base64(fig)
        
        print("\n" + "="*70)
        print("ğŸ“Š ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ!")
        print("="*70)
        print(f"âœ… ì´ë¯¸ì§€ íŒŒì¼: {filename}")
        print(f"âœ… Base64 ê¸¸ì´: {len(img_base64):,} ë¬¸ì")
        print("\nğŸ’¡ Claudeì—ê²Œ ë¶„ì„ ìš”ì²­ ì˜ˆì‹œ:")
        print("   'ë¹¨ê°„ ì ì„  = ì†Œì ˆ ì²« ë°• (1ë°•)")
        print("   'ì£¼í™© ì ì„  = ë‚˜ë¨¸ì§€ ë°• (2, 3, 4ë°•)")
        print("   'íšŒìƒ‰ ì ì„  = í¬ë¡œë§¤í‹± (8ë¶„ìŒí‘œ)")
        print("   'ë¹¨ê°„ ê³¡ì„  = íƒ€ê²© ê°•ë„ (ì—”ë²¨ë¡œí”„)")
        print()
        print("   ì´ í¬ë¡œë§¤í‹± ì—°ì£¼ê°€ ë©”íŠ¸ë¡œë†ˆì— ì–¼ë§ˆë‚˜ ì •í™•í•œì§€,")
        print("   ì–´ëŠ êµ¬ê°„ì´ ë¹ ë¥´ê³ /ëŠë¦°ì§€, ì „ì²´ ì •í™•ë„ %ë¡œ ë¶„ì„í•´ì¤˜'")
        print("="*70)
        
        plt.show()
        
        return filename, img_base64
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None, None

if __name__ == "__main__":
    record_and_analyze()
